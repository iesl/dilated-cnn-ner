#!/bin/bash

# Set up CoNLL-2003 train/test/dev data
export data_name="arxiv"
export raw_data_dir="$DATA_DIR/arxiv/"
export data_files=( "data.train" "data.testa" "data.testb" )
# todo get this number automagically
export max_sent_len=1100
export process_script="$DILATED_CNN_NER_ROOT/src/preprocessing/tsv_to_tfrecords.py"

export data_dir="$processed_data_dir/$data_name-w$filter_width-$embeddings_name"

if [[ "$start_end" == "true" ]]; then
    export data_dir="$data_dir-start_end"
fi

if [[ "$predict_pad" == "true" ]]; then
    export data_dir="$data_dir-pred_pad"
fi

if [[ "$documents" == "true" ]]; then
    export data_dir="$data_dir-docs"
fi

export train_dir="$data_dir/data.train"
export dev_dir="$data_dir/data.testa"
export test_dir="$data_dir/data.testb"

export maps_dir=$train_dir

export vocab_cutoff=4
export update_vocab_file="$DILATED_CNN_NER_ROOT/data/vocabs/${data_name}_cutoff_${vocab_cutoff}.txt"



